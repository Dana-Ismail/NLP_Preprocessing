{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ba3a00",
   "metadata": {},
   "source": [
    " ### NLP Notebook 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3375f01",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "### Read the sample.csv file and store it in a pandas dataframe called tweets_df.\n",
    "### Drop all colums in the dataframe except the text \n",
    "### Apply the following exercises for each text in the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9781110f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119237</td>\n",
       "      <td>105834</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 06:55:44 +0000 2017</td>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "      <td>119236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119238</td>\n",
       "      <td>ChaseSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 11 13:25:49 +0000 2017</td>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119239</td>\n",
       "      <td>105835</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:00:09 +0000 2017</td>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "      <td>119238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119240</td>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 10 15:16:08 +0000 2017</td>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "      <td>119241</td>\n",
       "      <td>119242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119241</td>\n",
       "      <td>105836</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 10 15:17:21 +0000 2017</td>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "      <td>119243</td>\n",
       "      <td>119240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id     author_id  inbound                      created_at  \\\n",
       "0    119237        105834     True  Wed Oct 11 06:55:44 +0000 2017   \n",
       "1    119238  ChaseSupport    False  Wed Oct 11 13:25:49 +0000 2017   \n",
       "2    119239        105835     True  Wed Oct 11 13:00:09 +0000 2017   \n",
       "3    119240  VirginTrains    False  Tue Oct 10 15:16:08 +0000 2017   \n",
       "4    119241        105836     True  Tue Oct 10 15:17:21 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @AppleSupport causing the reply to be disregar...            119236   \n",
       "1  @105835 Your business means a lot to us. Pleas...               NaN   \n",
       "2  @76328 I really hope you all change but I'm su...            119238   \n",
       "3  @105836 LiveChat is online at the moment - htt...            119241   \n",
       "4  @VirginTrains see attached error message. I've...            119243   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      NaN  \n",
       "1                 119239.0  \n",
       "2                      NaN  \n",
       "3                 119242.0  \n",
       "4                 119240.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "pd.options.mode.chained_assignment = None\n",
    "full_df = pd.read_csv(\"sample.csv\", nrows=5000)\n",
    "df = full_df[[\"text\"]]\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bba9b1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c99290",
   "metadata": {},
   "source": [
    "1. import nltk and download the ‘stopwords’ and ‘punkt’ packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd3fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words_nltk = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f09ace0",
   "metadata": {},
   "source": [
    "2. Import spacy and load the language model (use en_core_web_sm Language model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3608bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729b3eca",
   "metadata": {},
   "source": [
    "3. Toknize the text in the dataframe using NLTK. store the list of tokens for each text in the dataframe under the column : nltk_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37754f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nltk_tokens'] = df['text'].apply(lambda word: word_tokenize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a82ccef",
   "metadata": {},
   "source": [
    "3. Toknize the text in the dataframe using Spacy. store the list of tokens for each text in the dataframe under the column : Spacy_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0835cd3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c26441d2",
   "metadata": {},
   "source": [
    "5. Tokenizing the text into sentences with spaCy  and save the list of the sentences for each tweets_df[\"text\"]  in the dataframe. Save the the list of sentences in the dataframe under the column : Spacy_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a965bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "799eb838",
   "metadata": {},
   "source": [
    "5. Tokenizing the text into sentences with NLTK  and save the list of the sentences for each tweets_df[\"text\"]  in the dataframe. Save the the list of sentences in the dataframe under the column : Nltk_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1970bce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adc20cd5",
   "metadata": {},
   "source": [
    "7. Remove the  stopwords using nltk. Save the text without the stop words in the dataframe under without_stopwords_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32e497b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf4f3986",
   "metadata": {},
   "source": [
    "8. Remove the  stopwords using Spacy. Save the text without the stop words in the dataframe under without_stopwords_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c391c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7007987",
   "metadata": {},
   "source": [
    " 9. Perform stemming/ convert each token to it’s root form in the given text ( Stemming with nltk's PorterStemmer). Save the result under porter_stemmer column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b34733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f82f2251",
   "metadata": {},
   "source": [
    "10. Perform Lemmatization using spacy's. Save the result under lemma column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2897c061",
   "metadata": {},
   "source": [
    "11. Join the clean text and save it in the dataframe under the column clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d02cd86",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    " Read about NLTK and Spacy libraries and answer the following questions within 250 words for\n",
    "each:\n",
    "Please add resources and give your personal opinion.\n",
    "a. Which one is better in term of performance and speed? why?\n",
    "b. Can you use NLTK and Spacy to do text processing for Arabic language?\n",
    "c. Which one is well know that it is always updated and following the state of the art?\n",
    "d. What is the main advantage and disadvantage of each one?\n",
    "Some helpful Articles:\n",
    "\n",
    "NLTK : https://www.nltk.org\n",
    "\n",
    "Spacy : https://spacy.io\n",
    "\n",
    "Text normalization with spacy and NLTK\n",
    "\n",
    "https://towardsdatascience.com/text-normalization-with-spacy-and-nltk-1302ff430119\n",
    "\n",
    "Machine learning advancements in Arabic NLP\n",
    "\n",
    "https://towardsdatascience.com/machine-learning-advancements-in-arabic-nlp-c6982b2f602b\n",
    "\n",
    "NLTK VS Spacy\n",
    "\n",
    "https://www.activestate.com/blog/natural-language-processing-nltk-vs-spacy/\n",
    "\n",
    "Introduction to Libraries of NLP in Python — NLTK vs. spaCy\n",
    "\n",
    "https://medium.com/@akankshamalhotra24/introduction-to-libraries-of-nlp-in-python-nltk-vs-spacy-\n",
    "42d7b2f128f2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ededa7b72652456d364cf77fb33504d522693f4b345d4bcc4d531b95ed76b3a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
